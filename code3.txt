import com.google.api.services.bigquery.model.TableRow;
import com.google.cloud.bigquery.*;
import org.apache.beam.sdk.Pipeline;
import org.apache.beam.sdk.io.gcp.bigquery.BigQueryIO;
import org.apache.beam.sdk.transforms.MapElements;
import org.apache.beam.sdk.transforms.SimpleFunction;
import org.apache.beam.sdk.values.TypeDescriptors;

import java.util.UUID;

public class BeamBQTest {

    // TODO: Update these for your GCP project
    private static final String PROJECT_ID = "your-gcp-project-id";
    private static final String DATASET_ID = "beam_test_dataset";
    private static final String TABLE_ID = "test_table_" + UUID.randomUUID().toString().replace("-", "_");

    public static void main(String[] args) throws Exception {
        setupTestData();      // Step 1: Insert test data into BigQuery
        runBeamPipeline();    // Step 2: Read from BigQuery and print
    }

    private static void setupTestData() throws InterruptedException {
        System.out.println("Setting up test data...");

        BigQuery bigquery = BigQueryOptions.getDefaultInstance().getService();

        // 1. Create Table Schema
        Schema schema = Schema.of(
                Field.of("name", StandardSQLTypeName.STRING),
                Field.of("age", StandardSQLTypeName.INT64)
        );

        // 2. Create table in test dataset
        TableId tableId = TableId.of(DATASET_ID, TABLE_ID);
        TableDefinition tableDef = StandardTableDefinition.of(schema);
        TableInfo tableInfo = TableInfo.newBuilder(tableId, tableDef).build();
        bigquery.create(tableInfo);

        // 3. Insert sample rows
        InsertAllRequest insertRequest = InsertAllRequest.newBuilder(tableId)
                .addRow("row1", ImmutableMap.of("name", "Alice", "age", 30))
                .addRow("row2", ImmutableMap.of("name", "Bob", "age", 40))
                .build();

        InsertAllResponse response = bigquery.insertAll(insertRequest);

        if (response.hasErrors()) {
            System.err.println("Failed to insert rows into BQ:");
            response.getInsertErrors().forEach((key, err) -> System.err.println(err));
            throw new RuntimeException("BQ insert failed");
        }

        System.out.println("Test data inserted into table: " + TABLE_ID);
        Thread.sleep(5000); // Give BQ a few seconds to reflect data
    }

    private static void runBeamPipeline() {
        System.out.println("Running Beam pipeline...");

        Pipeline pipeline = Pipeline.create();

        String query = String.format("SELECT name, age FROM `%s.%s.%s`", PROJECT_ID, DATASET_ID, TABLE_ID);

        pipeline
            .apply("ReadFromBQ", BigQueryIO.readTableRows()
                .fromQuery(query)
                .usingStandardSql()
                .withMethod(BigQueryIO.TypedRead.Method.EXPORT) // Use EXPORT to avoid DIRECT_READ issues locally
                .withoutValidation())
            .apply("Print", MapElements.into(TypeDescriptors.strings())
                .via((TableRow row) -> {
                    System.out.println("Row: " + row);
                    return row.toString();
                }));

        pipeline.run().waitUntilFinish();
    }
}

